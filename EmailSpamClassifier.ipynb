{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0127bb08-9003-4239-8433-091b72f3efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imblearn in /home/disha/.local/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /home/disha/.local/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/lib/python3/dist-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/lib/python3/dist-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /home/disha/.local/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/disha/.local/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /home/disha/.local/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/disha/.local/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import kagglehub\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install imblearn --break-system-packages\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bf92b3f-14dc-47c4-9408-d6ae6f49148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"balaka18/email-spam-classification-dataset-csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd2cce99-6b16-4d4a-a481-fb2d99793da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file= [f for f in os.listdir(path) if f.endswith('.csv')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "daa94c70-f590-48cb-8784-187498627b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94191fc9-9762-44b4-853c-f9ecf1cc6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "Email No.     0\n",
      "the           0\n",
      "to            0\n",
      "ect           0\n",
      "and           0\n",
      "             ..\n",
      "military      0\n",
      "allowing      0\n",
      "ff            0\n",
      "dry           0\n",
      "Prediction    0\n",
      "Length: 3002, dtype: int64\n",
      "\n",
      "Data types:\n",
      "Email No.     object\n",
      "the            int64\n",
      "to             int64\n",
      "ect            int64\n",
      "and            int64\n",
      "               ...  \n",
      "military       int64\n",
      "allowing       int64\n",
      "ff             int64\n",
      "dry            int64\n",
      "Prediction     int64\n",
      "Length: 3002, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1bf3b0b8-a301-4cdc-90ef-0f3fc5b75a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"\\nUnique values in each column:\")\n",
    "#for col in df.columns:\n",
    "#    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "#    if df[col].nunique() < 10:  # Show unique values for categorical columns\n",
    "#        print(f\"  Values: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1c6911a-b9ee-4d0f-ad5b-3f799026a972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in 'Prediction':\n",
      "Prediction\n",
      "0    3672\n",
      "1    1500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution (percentage):\n",
      "Prediction\n",
      "0    70.99768\n",
      "1    29.00232\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nClass distribution in 'Prediction':\")\n",
    "print(df['Prediction'].value_counts())\n",
    "print(f\"\\nClass distribution (percentage):\")\n",
    "class_dist = df['Prediction'].value_counts(normalize=True) * 100\n",
    "print(class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e30c24c7-0951-4f27-8973-d0030912f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Target shape: (5172,)\n",
      "âœ“ Number of features: 3000\n",
      "âœ“ Feature data type: int64\n",
      "âœ“ Target data type: int64\n",
      "âœ“ Any missing values in features: 0\n",
      "âœ“ Any missing values in target: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_302219/1769405930.py:9: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"âœ“ Feature data type: {X.dtypes[0]}\")\n"
     ]
    }
   ],
   "source": [
    "#Data Preparation\n",
    "feature_cols = [col for col in df.columns if col not in ['Email No.', 'Prediction']]\n",
    "X = df[feature_cols]  # Features (word frequencies)\n",
    "y = df['Prediction']  # Target (0=Ham, 1=Spam)print(f\"âœ“ Features shape: {X.shape}\")\n",
    "print(f\"âœ“ Target shape: {y.shape}\")\n",
    "print(f\"âœ“ Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Check data types and any potential issues\n",
    "print(f\"âœ“ Feature data type: {X.dtypes[0]}\")\n",
    "print(f\"âœ“ Target data type: {y.dtype}\")\n",
    "print(f\"âœ“ Any missing values in features: {X.isnull().sum().sum()}\")\n",
    "print(f\"âœ“ Any missing values in target: {y.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2b0669d9-184d-4ef9-8595-33cca499303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4137 samples\n",
      "Test set size: 1035 samples\n",
      "Training set class distribution:\n",
      "Ham (0): 2937 (71.0%)\n",
      "Spam (1): 1200 (29.0%)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=42,stratify=y)\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Training set class distribution:\")\n",
    "print(f\"Ham (0): {(y_train == 0).sum()} ({(y_train == 0).mean():.1%})\")\n",
    "print(f\"Spam (1): {(y_train == 1).sum()} ({(y_train == 1).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24ae6286-03e6-4a13-b769-3e07ec8c7863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "699f9864-c239-4bec-8916-4debd0846cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='rbf', random_state=42, probability=True)\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0d3e4436-e114-4734-838e-1a6d3f18f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM training completed in 179.57 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_train_time = time.time() - start_time\n",
    "print(f\"SVM training completed in {svm_train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3fe1a13-81ae-43d1-9cfd-fdbf50bededa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression training completed in 2.40 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_train_time = time.time() - start_time\n",
    "print(f\"Logistic Regression training completed in {lr_train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e48ae4a-5aec-4e5f-96bb-75ddc180fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_pred = svm_model.predict(X_train_scaled)\n",
    "svm_test_pred = svm_model.predict(X_test_scaled)\n",
    "svm_test_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train_scaled)\n",
    "lr_test_pred = lr_model.predict(X_test_scaled)\n",
    "lr_test_proba = lr_model.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6692441-b3ba-4f87-b077-abc94cf5213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name, dataset_type):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} - {dataset_type} Performance:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"  Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"  F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ee750d4-15b7-42b8-a83b-d8b571d263a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM MODEL EVALUATION\n",
      "\n",
      "SVM - Training Performance:\n",
      "  Accuracy:  0.9683 (96.83%)\n",
      "  Precision: 0.9981 (99.81%)\n",
      "  Recall:    0.8925 (89.25%)\n",
      "  F1-Score:  0.9424 (94.24%)\n",
      "\n",
      "SVM - Test Performance:\n",
      "  Accuracy:  0.9304 (93.04%)\n",
      "  Precision: 0.9831 (98.31%)\n",
      "  Recall:    0.7733 (77.33%)\n",
      "  F1-Score:  0.8657 (86.57%)\n",
      "\n",
      "LOGISTIC REGRESSION MODEL EVALUATION\n",
      "\n",
      "Logistic Regression - Training Performance:\n",
      "  Accuracy:  0.9998 (99.98%)\n",
      "  Precision: 0.9992 (99.92%)\n",
      "  Recall:    1.0000 (100.00%)\n",
      "  F1-Score:  0.9996 (99.96%)\n",
      "\n",
      "Logistic Regression - Test Performance:\n",
      "  Accuracy:  0.9681 (96.81%)\n",
      "  Precision: 0.9211 (92.11%)\n",
      "  Recall:    0.9733 (97.33%)\n",
      "  F1-Score:  0.9465 (94.65%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSVM MODEL EVALUATION\")\n",
    "svm_train_acc, svm_train_prec, svm_train_rec, svm_train_f1 = evaluate_model(\n",
    "    y_train, svm_train_pred, \"SVM\", \"Training\"\n",
    ")\n",
    "svm_test_acc, svm_test_prec, svm_test_rec, svm_test_f1 = evaluate_model(\n",
    "    y_test, svm_test_pred, \"SVM\", \"Test\"\n",
    ")\n",
    "\n",
    "print(\"\\nLOGISTIC REGRESSION MODEL EVALUATION\")\n",
    "lr_train_acc, lr_train_prec, lr_train_rec, lr_train_f1 = evaluate_model(\n",
    "    y_train, lr_train_pred, \"Logistic Regression\", \"Training\"\n",
    ")\n",
    "lr_test_acc, lr_test_prec, lr_test_rec, lr_test_f1 = evaluate_model(\n",
    "    y_test, lr_test_pred, \"Logistic Regression\", \"Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa701a7d-de9d-4980-b2ed-87bd02f0a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now aggregating\n",
    "classifiers = {\n",
    "    'SVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Naive_Bayes': MultinomialNB(),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42, n_estimators=100),\n",
    "    'K_Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision_Tree': DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7acc23f3-a1b8-43ed-9f39-66d66d209170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM...\n",
      "Training completed in 251.95s\n",
      "Test Accuracy: 0.9304 (93.04%)\n",
      "\n",
      "Training Logistic Regression...\n",
      "Training completed in 2.36s\n",
      "Test Accuracy: 0.9681 (96.81%)\n",
      "\n",
      "Training Random Forest...\n",
      "Training completed in 2.69s\n",
      "Test Accuracy: 0.9652 (96.52%)\n",
      "\n",
      "Training Naive Bayes...\n",
      "Training completed in 0.20s\n",
      "Test Accuracy: 0.9420 (94.20%)\n",
      "\n",
      "Training AdaBoost...\n",
      "Training completed in 17.82s\n",
      "Test Accuracy: 0.9469 (94.69%)\n",
      "\n",
      "Training K Neighbors...\n",
      "Training completed in 31.92s\n",
      "Test Accuracy: 0.8338 (83.38%)\n",
      "\n",
      "Training Decision Tree...\n",
      "Training completed in 0.96s\n",
      "Test Accuracy: 0.8966 (89.66%)\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "training_times = {}\n",
    "individual_results = {}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining {name.replace('_', ' ')}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if name == 'Naive_Bayes':\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_pred = clf.predict(X_train)\n",
    "        test_pred = clf.predict(X_test)\n",
    "        test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        train_pred = clf.predict(X_train_scaled)\n",
    "        test_pred = clf.predict(X_test_scaled)\n",
    "        test_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    trained_models[name] = clf\n",
    "    training_times[name] = training_time\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    test_prec = precision_score(y_test, test_pred)\n",
    "    test_rec = recall_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "    individual_results[name] = {\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'test_precision': test_prec,\n",
    "        'test_recall': test_rec,\n",
    "        'test_f1': test_f1,\n",
    "        'training_time': training_time,\n",
    "        'predictions': test_pred,\n",
    "        'probabilities': test_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"Training completed in {training_time:.2f}s\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a8969e5-24c6-4a3f-9c60-972388d02788",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_data = []\n",
    "for name, results in individual_results.items():\n",
    "    performance_data.append({\n",
    "        'Model': name.replace('_', ' '),\n",
    "        'Test Accuracy': f\"{results['test_accuracy']:.4f}\",\n",
    "        'Test Precision': f\"{results['test_precision']:.4f}\",\n",
    "        'Test Recall': f\"{results['test_recall']:.4f}\",\n",
    "        'Test F1-Score': f\"{results['test_f1']:.4f}\",\n",
    "        'Training Time': f\"{results['training_time']:.2f}s\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bc728ca-c1f1-4609-bf1d-e7638521c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Individual Model Performance (sorted by accuracy):\n",
      "              Model Test Accuracy Test Precision Test Recall Test F1-Score Training Time\n",
      "Logistic Regression        0.9681         0.9211      0.9733        0.9465         2.36s\n",
      "      Random Forest        0.9652         0.9371      0.9433        0.9402         2.69s\n",
      "           AdaBoost        0.9469         0.9125      0.9033        0.9079        17.82s\n",
      "        Naive Bayes        0.9420         0.8681      0.9433        0.9042         0.20s\n",
      "                SVM        0.9304         0.9831      0.7733        0.8657       251.95s\n",
      "      Decision Tree        0.8966         0.7734      0.9100        0.8361         0.96s\n",
      "        K Neighbors        0.8338         0.6435      0.9567        0.7694        31.92s\n"
     ]
    }
   ],
   "source": [
    "performance_df = pd.DataFrame(performance_data)\n",
    "performance_df = performance_df.sort_values('Test Accuracy', ascending=False)\n",
    "print(\"\\nIndividual Model Performance (sorted by accuracy):\")\n",
    "print(performance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a6814eb-8464-4958-bc77-0eb3d44a5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ENSEMBLE MODEL PERFORMANCE (Majority Voting)\n",
      "==================================================\n",
      "Accuracy:  0.9758 (97.58%)\n",
      "Precision: 0.9421 (94.21%)\n",
      "Recall:    0.9767 (97.67%)\n",
      "F1-Score:  0.9591 (95.91%)\n"
     ]
    }
   ],
   "source": [
    "all_predictions = {}\n",
    "for name, results in individual_results.items():\n",
    "    all_predictions[name] = results['predictions']\n",
    "prediction_matrix = np.column_stack([all_predictions[name] for name in classifiers.keys()])\n",
    "\n",
    "def majority_vote(predictions_matrix):\n",
    "    majority_predictions = []\n",
    "    vote_counts = []\n",
    "    \n",
    "    for i in range(predictions_matrix.shape[0]):\n",
    "        sample_predictions = predictions_matrix[i, :]\n",
    "        vote_count = Counter(sample_predictions)\n",
    "        majority_class = vote_count.most_common(1)[0][0]\n",
    "        majority_predictions.append(majority_class)\n",
    "        vote_counts.append(dict(vote_count))\n",
    "    \n",
    "    return np.array(majority_predictions), vote_counts\n",
    "\n",
    "# Apply majority voting\n",
    "ensemble_predictions, vote_details = majority_vote(prediction_matrix)\n",
    "\n",
    "# Evaluate ensemble performance\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "ensemble_precision = precision_score(y_test, ensemble_predictions)\n",
    "ensemble_recall = recall_score(y_test, ensemble_predictions)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENSEMBLE MODEL PERFORMANCE (Majority Voting)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {ensemble_accuracy:.4f} ({ensemble_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {ensemble_precision:.4f} ({ensemble_precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {ensemble_recall:.4f} ({ensemble_recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {ensemble_f1:.4f} ({ensemble_f1*100:.2f}%)\")\n",
    "\n",
    "ensemble_data = {\n",
    "    'Model': 'Ensemble (Majority Vote)',\n",
    "    'Test Accuracy': f\"{ensemble_accuracy:.4f}\",\n",
    "    'Test Precision': f\"{ensemble_precision:.4f}\",\n",
    "    'Test Recall': f\"{ensemble_recall:.4f}\",\n",
    "    'Test F1-Score': f\"{ensemble_f1:.4f}\",\n",
    "    'Training Time': 'N/A'\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
